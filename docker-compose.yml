services:
  redis:
      image: redis:7-alpine
      container_name: pyspark-llm-redis
      restart: unless-stopped
  backend:
    build: ./backend
    container_name: pyspark-llm-backend
    env_file:
      - ./backend/.env
    ports:
      - "8050:8000"
    volumes:
      - ./backend:/app
    depends_on:
      - redis
    restart: unless-stopped
    healthcheck:
      test: ["CMD-SHELL", "python -c 'import urllib.request; urllib.request.urlopen(\"http://localhost:8000/docs\")'"]
  worker:  
    build: ./backend 
    container_name: pyspark-llm-worker
    command: celery -A app.workers.tasks.celery worker --loglevel=info --concurrency=1
    env_file:
      - ./backend/.env
    volumes:
      - ./backend:/app
    depends_on:
      - redis
    restart: unless-stopped
  frontend:
    build: ./frontend
    container_name: pyspark-llm-frontend
    ports:
      - "8501:8501"
    depends_on:
      backend:
        condition: service_healthy
    restart: unless-stopped
    volumes:
      - ./frontend:/app